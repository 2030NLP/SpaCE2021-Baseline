{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_dataset(dataset, flag):\n",
    "    with open(flag + \".json\", \"w\") as fw:\n",
    "        json.dump(dataset, fw, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一版Task1数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat datasets for Task1\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 原始数据集文件名\n",
    "raw_file_name = \"./QAs.json\"\n",
    "with open(raw_file_name, \"r\") as fr:\n",
    "    data = json.load(fr)\n",
    "    \n",
    "# 划分数据集\n",
    "train, res = train_test_split(data, train_size=0.8, random_state=3)\n",
    "test, val = train_test_split(res, train_size=0.5, random_state=3)\n",
    "\n",
    "# 保存\n",
    "save_dataset(train, \"train\")\n",
    "save_dataset(test, \"test\")\n",
    "save_dataset(val, \"val\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20210307 Task1数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of datasets train:4237, test:806, dev:794\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def save_dataset(dataset, flag):\n",
    "    with open(flag + \".json\", \"w\") as fw:\n",
    "        json.dump(dataset, fw, indent=2, ensure_ascii=False)\n",
    "        \n",
    "\n",
    "# 原始数据集文件名\n",
    "raw_file_name = \"./task1(1).json\"\n",
    "with open(raw_file_name, \"r\") as fr:\n",
    "    data = json.load(fr)\n",
    "    question = data[\"questions\"]\n",
    "\n",
    "# 数据集划分\n",
    "train = [item for item in question if item[\"set\"] == \"train\" ]\n",
    "test = [item for item in question if item[\"set\"] == \"test\"]\n",
    "dev = [item for item in question if item[\"set\"] == \"dev\"]\n",
    "\n",
    "# 保存\n",
    "save_dataset(train, \"train\")\n",
    "save_dataset(test, \"test\")\n",
    "save_dataset(dev, \"dev\")\n",
    "\n",
    "# 输出统计值\n",
    "print(\"size of datasets train:{}, test:{}, dev:{}\".format(len(train),len(test),len(dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20210307 Task3数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of datasets train:8534, test:2985, dev:2969\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def save_dataset(dataset, flag):\n",
    "    with open(flag + \".json\", \"w\") as fw:\n",
    "        json.dump(dataset, fw, indent=2, ensure_ascii=False)\n",
    "        \n",
    "\n",
    "# 原始数据集文件名\n",
    "raw_file_name = \"./task3(4).json\"\n",
    "with open(raw_file_name, \"r\") as fr:\n",
    "    data = json.load(fr)\n",
    "    question = data[\"questions\"]\n",
    "\n",
    "# 数据集划分\n",
    "train = [item for item in question if item[\"set\"] == \"train\" ]\n",
    "test = [item for item in question if item[\"set\"] == \"test\"]\n",
    "dev = [item for item in question if item[\"set\"] == \"dev\"]\n",
    "\n",
    "# 保存\n",
    "save_dataset(train, \"train\")\n",
    "save_dataset(test, \"test\")\n",
    "save_dataset(dev, \"dev\")\n",
    "\n",
    "# 输出统计值\n",
    "print(\"size of datasets train:{}, test:{}, dev:{}\".format(len(train),len(test),len(dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size of datasets train:10925, test:2963, dev:2988"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一版数据生成的Task2数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-filtered num of positive:7060, num of negative:115155\n",
      "pre-filtered num of positive:898, num of negative:14492\n",
      "pre-filtered num of positive:867, num of negative:14599\n",
      "final num: train:14120, test:15390, val:15466\n"
     ]
    }
   ],
   "source": [
    "# create datasets for Task2\n",
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def save_dataset(dataset, flag):\n",
    "    with open(flag + \".json\", \"w\") as fw:\n",
    "        json.dump(dataset, fw, indent=2, ensure_ascii=False)\n",
    "\n",
    "def get_sample(dataset, mode):\n",
    "    positive = []\n",
    "    negative = []\n",
    "    \n",
    "    for item in dataset:\n",
    "        for idx, ans in enumerate(item[\"reasonAnswers\"]):\n",
    "            if idx in item[\"reasonKey\"]:\n",
    "                positive.append({\"text\":item[\"materialText\"], \"answer\":ans[3:], \"label\":1})\n",
    "            else:\n",
    "                negative.append({\"text\":item[\"materialText\"], \"answer\":ans[3:], \"label\":0})            \n",
    "    print(\"pre-filtered num of positive:{}, num of negative:{}\".format(len(positive), len(negative)))\n",
    "    \n",
    "    # 随机抽负样本，使得负样本数量与正样本保持一致\n",
    "    if mode == 0:\n",
    "        negative = random.sample(negative, len(positive))\n",
    "    total = positive + negative\n",
    "    # random.shuffle()无返回值\n",
    "    random.shuffle(total)\n",
    "    return total\n",
    "\n",
    "raw_file_name = \"./QAs.json\"\n",
    "with open(raw_file_name, \"r\") as fr:\n",
    "    data = json.load(fr)\n",
    "\n",
    "new_data = [item for item in data if item[\"judgementKey\"] != 1]\n",
    "train, res = train_test_split(data, train_size=0.8, random_state=3)\n",
    "test, dev = train_test_split(res, train_size=0.5, random_state=3)\n",
    "\n",
    "train = get_sample(train, 0)\n",
    "test = get_sample(test, 1)\n",
    "dev = get_sample(dev, 1)\n",
    "print(\"final num: train:{}, test:{}, val:{}\".format(len(train), len(test), len(dev)))\n",
    "\n",
    "save_dataset(train, \"train\")\n",
    "save_dataset(test, \"test\")\n",
    "save_dataset(dev, \"dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二版原数据生成的Task2数据集\n",
    "注：文件中字段的组织有变动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-filtered num of positive:8036, num of negative:86821\n",
      "pre-filtered num of positive:981, num of negative:10846\n",
      "pre-filtered num of positive:1007, num of negative:10725\n",
      "final num: train:16072, test:11827, val:11732\n"
     ]
    }
   ],
   "source": [
    "# create datasets for Task2\n",
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def save_dataset(dataset, flag):\n",
    "    with open(flag + \".json\", \"w\") as fw:\n",
    "        json.dump(dataset, fw, indent=2, ensure_ascii=False)\n",
    "\n",
    "def get_sample(dataset, mode):\n",
    "    positive = []\n",
    "    negative = []\n",
    "    \n",
    "    for item in dataset:\n",
    "        for idx, ans in enumerate(item[\"reasons\"]):\n",
    "            if ans[\"judge2\"] == 1:\n",
    "                positive.append({\"text\":item[\"context\"], \"answer\":ans[\"content\"], \"label\":1, \"type\":ans[\"type\"]})\n",
    "            else:\n",
    "                negative.append({\"text\":item[\"context\"], \"answer\":ans[\"content\"], \"label\":0, \"type\":ans[\"type\"]})            \n",
    "    print(\"pre-filtered num of positive:{}, num of negative:{}\".format(len(positive), len(negative)))\n",
    "    \n",
    "    # 随机抽负样本，使得负样本数量与正样本保持一致\n",
    "    if mode == 0:\n",
    "        negative = random.sample(negative, len(positive))\n",
    "    total = positive + negative\n",
    "    # random.shuffle()无返回值\n",
    "    random.shuffle(total)\n",
    "    return total\n",
    "\n",
    "raw_file_name = \"./QAs2.json\"\n",
    "with open(raw_file_name, \"r\") as fr:\n",
    "    data = json.load(fr)\n",
    "\n",
    "new_data = [item for item in data if item[\"judge1\"] != 1]\n",
    "train, res = train_test_split(data, train_size=0.8, random_state=3)\n",
    "test, dev = train_test_split(res, train_size=0.5, random_state=3)\n",
    "\n",
    "train = get_sample(train, 0)\n",
    "test = get_sample(test, 1)\n",
    "dev = get_sample(dev, 1)\n",
    "print(\"final num: train:{}, test:{}, val:{}\".format(len(train), len(test), len(dev)))\n",
    "\n",
    "save_dataset(train, \"train\")\n",
    "save_dataset(test, \"test\")\n",
    "save_dataset(dev, \"dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新Task2数据集生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final num: train:1531, test:300, dev:289\n",
      "final num: train:1531, test:300, dev:289\n"
     ]
    }
   ],
   "source": [
    "# create datasets for Task2\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "\n",
    "def save_dataset(dataset, flag):\n",
    "    with open(flag + \".json\", \"w\") as fw:\n",
    "        json.dump(dataset, fw, indent=2, ensure_ascii=False)\n",
    "\n",
    "        \n",
    "def get_sample(dataset):\n",
    "    ret = []\n",
    "    for item in dataset:\n",
    "        \n",
    "        ori = item[\"content\"]\n",
    "        extraction = re.findall(r'【【([\\u4e00-\\u9fa5]+)→([\\u4e00-\\u9fa5]+)】】',ori)\n",
    "        pre, substitute = extraction[0]\n",
    "        res = re.sub(r'【【[\\u4e00-\\u9fa5]+→[\\u4e00-\\u9fa5]+】】', \"[MASK]\" * len(substitute), ori)\n",
    "        item[\"prd_context\"] = res\n",
    "        item[\"pre\"] = pre\n",
    "        item[\"substitute\"] = substitute\n",
    "        item[\"label\"] = 1 if item[\"judge_e\"] == \"变化不大\" else 0\n",
    "        ret.append(item)\n",
    "    \n",
    "    return ret\n",
    "        \n",
    "\n",
    "raw_file_name = \"./task2(1).json\"\n",
    "with open(raw_file_name, \"r\") as fr:\n",
    "    raw = json.load(fr)\n",
    "    data = raw[\"questions\"]\n",
    "\n",
    "train = [d for d in data if d[\"set\"] == \"train\"]\n",
    "dev = [d for d in data if d[\"set\"] == \"dev\"]\n",
    "test = [d for d in data if d[\"set\"] == \"test\"]\n",
    "print(\"final num: train:{}, test:{}, dev:{}\".format(len(train), len(test), len(dev)))\n",
    "\n",
    "train = get_sample(train)\n",
    "dev = get_sample(dev)\n",
    "test = get_sample(test)\n",
    "print(\"final num: train:{}, test:{}, dev:{}\".format(len(train), len(test), len(dev)))\n",
    "\n",
    "save_dataset(train, \"train\")\n",
    "save_dataset(dev, \"dev\")\n",
    "save_dataset(dev, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task4测试集生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num dev:1305,test:1360\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "raw_file_name = \"./task4(3).json\"\n",
    "with open(raw_file_name, \"r\") as fr:\n",
    "    raw = json.load(fr)\n",
    "    data = raw[\"questions\"]\n",
    "    \n",
    "dev = [item for item in data if item[\"set\"] == \"dev\"]\n",
    "test = [item for item in data if item[\"set\"] == \"test\"]\n",
    "\n",
    "with open(\"./united_dev.json\",\"w\") as fw:\n",
    "    json.dump(dev, fw, indent=2, ensure_ascii=False)\n",
    "    \n",
    "with open(\"./united_test.json\",\"w\") as fw:\n",
    "    json.dump(test,fw,indent=2, ensure_ascii=False)\n",
    "    \n",
    "print(\"num dev:{},test:{}\".format(len(dev), len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:364, answer:107, total:415\n"
     ]
    }
   ],
   "source": [
    "# 统计最长句子\n",
    "def get_max_length():\n",
    "    max_length = 0\n",
    "    for d in data:\n",
    "        if len(d['context']) > max_length:\n",
    "            max_length = len(d['text'])\n",
    "    return max_length\n",
    "\n",
    "def get_data(file_path):\n",
    "    with open(file_path, \"r\") as fr:\n",
    "        data = json.load(fr)\n",
    "    return data\n",
    "    \n",
    "def get_statistics():\n",
    "    max_text_len = 0\n",
    "    max_ans_len = 0\n",
    "    max_total_len = 0\n",
    "    \n",
    "    data = []\n",
    "    data.extend(get_data(\"./train.json\"))\n",
    "    data.extend(get_data(\"./dev.json\"))\n",
    "    data.extend(get_data(\"./test.json\"))\n",
    "    \n",
    "    for d in data:\n",
    "        max_text_len = max(len(d['text']), max_text_len)\n",
    "        max_ans_len = max(len(d['answer']), max_ans_len)\n",
    "        max_total_len = max(len(d['text'])+ len(d['answer']), max_total_len)\n",
    "    print(\"text:{}, answer:{}, total:{}\".format(max_text_len, max_ans_len, max_total_len))\n",
    "get_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
