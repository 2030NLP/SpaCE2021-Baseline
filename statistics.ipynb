{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1模型预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-eff23bec1ccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# total\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "with open(\"./BERT-Linear/data/prediction.json\", \"r\") as fr:\n",
    "    data = json.load(fr)\n",
    "tp = fp = fn = tn = 0\n",
    "for item in data:\n",
    "    \n",
    "    if item[\"prediction\"] == 1:\n",
    "        # 正样本，预测为正--正确\n",
    "        if item[\"groundTruth\"] == 1:\n",
    "            tp += 1\n",
    "            score_dict[t][0] += 1\n",
    "        # 负样本，预测为正--错误\n",
    "        else:\n",
    "            fp += 1\n",
    "            score_dict[t][1] += 1\n",
    "    else:\n",
    "        # 正样本，预测为负--错误\n",
    "        if item[\"groundTruth\"] == 1:\n",
    "            fn += 1\n",
    "            score_dict[t][2] += 1\n",
    "        # 负样本，预测为负--正确\n",
    "        else:\n",
    "            tn += 1\n",
    "            score_dict[t][3] += 1\n",
    "# total\n",
    "acc = (tp + tn)/(tp + fp + fn + tn)\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp + fn)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print(\"total\\t accuracy:{:.6f},\\t precision:{:.6f},\\t recall:{:.6f},\\t f1:{:.6f}\".format(acc,precision,recall,f1))\n",
    "print(\"         tp \\t fp \\t fn \\t tn\")    \n",
    "print(\"total    {} \\t {} \\t {} \\t {}\".format(tp, fp, fn, tn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task2模型预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total\t accuracy:0.937262,\t precision:0.574548,\t recall:0.938838,\t f1:0.712848\n",
      "typeA \t accuracy:0.781442,\t precision:0.591528,\t recall:0.963054,\t f1:0.732896\n",
      "typeB \t accuracy:0.979386,\t precision:0.722222,\t recall:0.946602,\t f1:0.819328\n",
      "typeC1 \t accuracy:0.950166,\t precision:0.645963,\t recall:0.971963,\t f1:0.776119\n",
      "typeC2 \t accuracy:0.815385,\t precision:0.837398,\t recall:0.962617,\t f1:0.895652\n",
      "typeD \t accuracy:0.947294,\t precision:0.333333,\t recall:0.873950,\t f1:0.482599\n",
      "typeE \t accuracy:0.918575,\t precision:0.315789,\t recall:0.666667,\t f1:0.428571\n",
      "         tp \t fp \t fn \t tn\n",
      "total    921 \t 682 \t 60 \t 10164\n",
      "A \t 391 \t 270 \t 15 \t 628\n",
      "B \t 195 \t 75 \t 11 \t 3891\n",
      "C1 \t 104 \t 57 \t 3 \t 1040\n",
      "C2 \t 103 \t 20 \t 4 \t 3\n",
      "D \t 104 \t 208 \t 15 \t 3904\n",
      "E \t 24 \t 52 \t 12 \t 698\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "with open(\"./BERT-Linear3/data/prediction.json\", \"r\") as fr:\n",
    "    data = json.load(fr)\n",
    "type_list = ['A', 'B', 'C1', 'C2', 'D', 'E']\n",
    "# type_list = ['A', 'B', 'C1', 'C2', 'D1', 'D2', 'D', 'E']\n",
    "# 保存每种不同type的tp,tn,fp,fn\n",
    "score_dict = {}\n",
    "for t in type_list:\n",
    "    score_dict[t] = [0,0,0,0]\n",
    "tp = fp = fn = tn = 0\n",
    "for item in data:\n",
    "    t = \"D\" if item[\"type\"][0] == 'D' else item[\"type\"]\n",
    "    if item[\"prediction\"] == 1:\n",
    "        # 正样本，预测为正--正确\n",
    "        if item[\"label\"] == 1:\n",
    "            tp += 1\n",
    "            score_dict[t][0] += 1\n",
    "        # 负样本，预测为正--错误\n",
    "        else:\n",
    "            fp += 1\n",
    "            score_dict[t][1] += 1\n",
    "    else:\n",
    "        # 正样本，预测为负--错误\n",
    "        if item[\"label\"] == 1:\n",
    "            fn += 1\n",
    "            score_dict[t][2] += 1\n",
    "        # 负样本，预测为负--正确\n",
    "        else:\n",
    "            tn += 1\n",
    "            score_dict[t][3] += 1\n",
    "# total\n",
    "acc = (tp + tn)/(tp + fp + fn + tn)\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp + fn)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print(\"total\\t accuracy:{:.6f},\\t precision:{:.6f},\\t recall:{:.6f},\\t f1:{:.6f}\".format(acc,precision,recall,f1))\n",
    "# each type\n",
    "for k,v in score_dict.items():\n",
    "    acc = (v[0] + v[3])/sum(v)\n",
    "    precision = v[0]/(v[0] + v[1])\n",
    "#     recall = v[0]/(v[0] + v[2]) if (v[0] + v[2])>0 else 0\n",
    "#     f1 = 2 * precision * recall / (precision + recall) if (precision + recall)!= 0 else 0\n",
    "    recall = v[0]/(v[0] + v[2])\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    print(\"type{} \\t accuracy:{:.6f},\\t precision:{:.6f},\\t recall:{:.6f},\\t f1:{:.6f}\".format(k, acc,precision,recall,f1))\n",
    "\n",
    "print(\"         tp \\t fp \\t fn \\t tn\")\n",
    "print(\"total    {} \\t {} \\t {} \\t {}\".format(tp, fp, fn, tn))\n",
    "for k,v in score_dict.items():\n",
    "    print(\"{} \\t {} \\t {} \\t {} \\t {}\".format(k,v[0],v[1],v[2],v[3]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机筛去9/10的负样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total\t accuracy:0.937273,\t precision:0.921922,\t recall:0.938838,\t f1:0.930303\n",
      "typeA \t accuracy:0.908722,\t precision:0.928741,\t recall:0.963054,\t f1:0.945586\n",
      "typeB \t accuracy:0.973490,\t precision:0.965347,\t recall:0.946602,\t f1:0.955882\n",
      "typeC1 \t accuracy:0.962963,\t precision:0.954128,\t recall:0.971963,\t f1:0.962963\n",
      "typeC2 \t accuracy:0.936937,\t precision:0.971698,\t recall:0.962617,\t f1:0.967136\n",
      "typeD \t accuracy:0.923744,\t precision:0.781955,\t recall:0.873950,\t f1:0.825397\n",
      "typeE \t accuracy:0.870968,\t precision:0.857143,\t recall:0.666667,\t f1:0.750000\n",
      "         tp \t fp \t fn \t tn\n",
      "total    921 \t 78 \t 60 \t 1141\n",
      "A \t 391 \t 30 \t 15 \t 57\n",
      "B \t 195 \t 7 \t 11 \t 466\n",
      "C1 \t 104 \t 5 \t 3 \t 104\n",
      "C2 \t 103 \t 3 \t 4 \t 1\n",
      "D \t 104 \t 29 \t 15 \t 429\n",
      "E \t 24 \t 4 \t 12 \t 84\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "with open(\"./BERT-Linear3/data/prediction.json\", \"r\") as fr:\n",
    "    data = json.load(fr)\n",
    "type_list = ['A', 'B', 'C1', 'C2', 'D', 'E']\n",
    "# type_list = ['A', 'B', 'C1', 'C2', 'D1', 'D2', 'D', 'E']\n",
    "# 保存每种不同type的tp,tn,fp,fn\n",
    "score_dict = {}\n",
    "for t in type_list:\n",
    "    score_dict[t] = [0,0,0,0]\n",
    "tp = fp = fn = tn = 0\n",
    "for item in data:\n",
    "    t = \"D\" if item[\"type\"][0] == 'D' else item[\"type\"]\n",
    "    if item[\"prediction\"] == 1:\n",
    "        # 正样本，预测为正--正确\n",
    "        if item[\"label\"] == 1:\n",
    "            tp += 1\n",
    "            score_dict[t][0] += 1\n",
    "        # 负样本，预测为正--错误\n",
    "        else:\n",
    "            if random.randint(0,100) <= 10:\n",
    "                fp += 1\n",
    "                score_dict[t][1] += 1\n",
    "    else:\n",
    "        # 正样本，预测为负--错误\n",
    "        if item[\"label\"] == 1:\n",
    "            fn += 1\n",
    "            score_dict[t][2] += 1\n",
    "        # 负样本，预测为负--正确\n",
    "        else:\n",
    "            if random.randint(0,100) <= 10:\n",
    "                tn += 1\n",
    "                score_dict[t][3] += 1\n",
    "# total\n",
    "acc = (tp + tn)/(tp + fp + fn + tn)\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp + fn)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print(\"total\\t accuracy:{:.6f},\\t precision:{:.6f},\\t recall:{:.6f},\\t f1:{:.6f}\".format(acc,precision,recall,f1))\n",
    "# each type\n",
    "for k,v in score_dict.items():\n",
    "    acc = (v[0] + v[3])/sum(v)\n",
    "    precision = v[0]/(v[0] + v[1])\n",
    "#     recall = v[0]/(v[0] + v[2]) if (v[0] + v[2])>0 else 0\n",
    "#     f1 = 2 * precision * recall / (precision + recall) if (precision + recall)!= 0 else 0\n",
    "    recall = v[0]/(v[0] + v[2])\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    print(\"type{} \\t accuracy:{:.6f},\\t precision:{:.6f},\\t recall:{:.6f},\\t f1:{:.6f}\".format(k, acc,precision,recall,f1))\n",
    "\n",
    "print(\"         tp \\t fp \\t fn \\t tn\")\n",
    "print(\"total    {} \\t {} \\t {} \\t {}\".format(tp, fp, fn, tn))\n",
    "for k,v in score_dict.items():\n",
    "    print(\"{} \\t {} \\t {} \\t {} \\t {}\".format(k,v[0],v[1],v[2],v[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 联合任务准确率统计（macro-f1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-f1:0.517037\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"./BERT-Linear2/data/united_test.json\", \"r\") as fr:\n",
    "    data = json.load(fr)\n",
    "# tf ff ft\n",
    "gt_tf = 0\n",
    "gt_ff = 0\n",
    "gt_ft = 0\n",
    "\n",
    "p_tf = 0\n",
    "p_ff = 0\n",
    "p_ft = 0\n",
    "\n",
    "c_tf = 0\n",
    "c_ff = 0\n",
    "c_ft = 0\n",
    "for item in data:\n",
    "    \n",
    "    if item[\"judge1\"] == True:\n",
    "        gt_tf += 1\n",
    "        gt = \"tf\"\n",
    "    else:\n",
    "        if item[\"judge2\"] == True:\n",
    "            gt_ft += 1\n",
    "            gt = \"ft\"\n",
    "        else:\n",
    "            gt_ff += 1\n",
    "            gt = \"ff\"\n",
    "    \n",
    "    if item[\"pred1\"] == 1:\n",
    "        p_tf += 1\n",
    "        p = \"tf\"\n",
    "    else:\n",
    "        if item[\"pred2\"] == 1:\n",
    "            p_ft += 1\n",
    "            p = \"ft\"\n",
    "        else:\n",
    "            p_ff += 1\n",
    "            p = \"ff\"\n",
    "            \n",
    "    if gt == p:\n",
    "        if gt == \"tf\":\n",
    "            c_tf += 1\n",
    "        elif gt == \"ft\":\n",
    "            c_ft += 1\n",
    "        else:\n",
    "            c_ff += 1\n",
    "            \n",
    "precision_tf = c_tf / p_tf\n",
    "recall_tf = c_tf / gt_tf\n",
    "f1_tf = 2 * precision_tf * recall_tf / (precision_tf + recall_tf)\n",
    "\n",
    "precision_ft = c_ft / p_ft\n",
    "recall_ft = c_ft / gt_ft\n",
    "f1_ft = 2 * precision_ft * recall_ft / (precision_ft + recall_ft)\n",
    "\n",
    "precision_ff = c_ff / p_ff\n",
    "recall_ff = c_ff /gt_ff\n",
    "f1_ff = 2 * precision_ff * recall_ff / (precision_ff + recall_ff)\n",
    "\n",
    "print(\"Macro-f1:{:.6f}\".format((f1_tf + f1_ft + f1_ff) / 3))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 联合任务准确率计算（micro-f1？）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "united test precision:0.588055, recall:0.513369, f1:0.548180\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"./BERT-Linear2/data/united_dev.json\", \"r\") as fr:\n",
    "    data = json.load(fr)\n",
    "# tf ff ft\n",
    "gt_tf = 0\n",
    "gt_ff = 0\n",
    "gt_ft = 0\n",
    "\n",
    "p_tf = 0\n",
    "p_ff = 0\n",
    "p_ft = 0\n",
    "\n",
    "c_tf = 0\n",
    "c_ff = 0\n",
    "c_ft = 0\n",
    "\n",
    "tp = fp = tn = fn = 0\n",
    "for item in data:\n",
    "    \n",
    "    \n",
    "    if item[\"judge1\"] == True:\n",
    "        gt_tf += 1\n",
    "        gt = \"tf\"\n",
    "    else:\n",
    "        if item[\"judge2\"] == True:\n",
    "            gt_ft += 1\n",
    "            gt = \"ft\"\n",
    "        else:\n",
    "            gt_ff += 1\n",
    "            gt = \"ff\"\n",
    "    \n",
    "    if item[\"pred1\"] == 1:\n",
    "        p_tf += 1\n",
    "        p = \"tf\"\n",
    "    else:\n",
    "        if item[\"pred2\"] == 1:\n",
    "            p_ft += 1\n",
    "            p = \"ft\"\n",
    "        else:\n",
    "            p_ff += 1\n",
    "            p = \"ff\"\n",
    "            \n",
    "    if gt == p:\n",
    "        \n",
    "        if gt == \"tf\":\n",
    "            c_tf += 1\n",
    "        elif gt == \"ft\":\n",
    "            c_ft += 1\n",
    "        else:\n",
    "            c_ff += 1\n",
    "            \n",
    "# precision：归因正确的/自己认为需要归因的\n",
    "#     自己认为需要归因的：模型1预测为负的案例（模型做了归因的）\n",
    "# recall：归因正确的/真正需要归因的\n",
    "#     真正需要归因的：真正为负的案例\n",
    "precision = ((c_ft + c_ff)/(p_ft + p_ff)) if (p_ft + p_ff)!=0 else 0\n",
    "recall = ((c_ft + c_ff)/(gt_ft + gt_ff)) if (gt_ft + gt_ff) !=0 else 0\n",
    "f1 = (2 * precision * recall / (precision + recall)) if (precision + recall)!=0 else 0\n",
    "print(\"united test precision:{:.6f}, recall:{:.6f}, f1:{:.6f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
